{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Data Science\\\\END to END Proj\\\\NVDNLP'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd\n",
    "os.chdir(\"../\")\n",
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "#     ENTITY: MODEL TRAINER CONFIG\n",
    "# ============================================\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    model_dir: Path\n",
    "    trained_model_path: Path\n",
    "    n_estimators: int\n",
    "    learning_rate: float\n",
    "    max_depth: int\n",
    "    subsample: float\n",
    "    colsample_bytree: float\n",
    "    random_state: int\n",
    "    tree_method: str\n",
    "    eval_metric: str\n",
    "    early_stopping_rounds: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# âš™ï¸ CONFIGURATION MANAGER\n",
    "# ============================================\n",
    "\n",
    "from src.NVDNLP.utils.common import read_yaml, create_directories \n",
    "# from src.NVDNLP.entity.config_entity import ModelTrainerConfig\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = \"config/config.yaml\",\n",
    "        params_filepath = \"params.yaml\",\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.XGBoost\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            model_dir=Path(config.model_dir),\n",
    "            trained_model_path=Path(config.trained_model_path),\n",
    "            n_estimators=params.n_estimators,\n",
    "            learning_rate=params.learning_rate,\n",
    "            max_depth=params.max_depth,\n",
    "            subsample=params.subsample,\n",
    "            colsample_bytree=params.colsample_bytree,\n",
    "            random_state=params.random_state,\n",
    "            tree_method=params.tree_method,\n",
    "            eval_metric=params.eval_metric,\n",
    "            early_stopping_rounds=params.early_stopping_rounds\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ðŸ¤– MODEL TRAINER COMPONENT\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "# from src.NVDNLP.entity.config_entity import ModelTrainerConfig\n",
    "from src.NVDNLP import logger\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig, train_data, test_data, label_encoder, tfidf_vectorizer):\n",
    "        self.config = config\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.label_encoder = label_encoder\n",
    "        self.tfidf_vectorizer = tfidf_vectorizer\n",
    "        self.model = None\n",
    "\n",
    "    def _check_model_exists(self) -> bool:\n",
    "        \"\"\"Check if model already exists in artifacts/model_training\"\"\"\n",
    "        return os.path.exists(self.config.trained_model_path)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare training and testing data\"\"\"\n",
    "        try:\n",
    "            logger.info(\" Preparing data for model training...\")\n",
    "            \n",
    "            # Extract features and labels from train data\n",
    "            X_train_tfidf = self.tfidf_vectorizer.transform(self.train_data['Description'].astype(str))\n",
    "            y_train = self.train_data['encoded_severity']\n",
    "            \n",
    "            # Extract features and labels from test data\n",
    "            X_test_tfidf = self.tfidf_vectorizer.transform(self.test_data['Description'].astype(str))\n",
    "            y_test = self.test_data['encoded_severity']\n",
    "            \n",
    "            logger.info(f\" Training data: {X_train_tfidf.shape}, {len(y_train)} samples\")\n",
    "            logger.info(f\" Testing data: {X_test_tfidf.shape}, {len(y_test)} samples\")\n",
    "            \n",
    "            return X_train_tfidf, X_test_tfidf, y_train, y_test\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\" Data preparation failed: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def initialize_model(self):\n",
    "        \"\"\"Initialize XGBoost classifier with configuration\"\"\"\n",
    "        try:\n",
    "            logger.info(\" Initializing XGBoost model...\")\n",
    "            \n",
    "            self.model = xgb.XGBClassifier(\n",
    "                n_estimators=self.config.n_estimators,\n",
    "                learning_rate=self.config.learning_rate,\n",
    "                max_depth=self.config.max_depth,\n",
    "                subsample=self.config.subsample,\n",
    "                colsample_bytree=self.config.colsample_bytree,\n",
    "                random_state=self.config.random_state,\n",
    "                tree_method=self.config.tree_method,\n",
    "                eval_metric=self.config.eval_metric,\n",
    "                early_stopping_rounds=self.config.early_stopping_rounds\n",
    "            )\n",
    "            \n",
    "            logger.info(\" XGBoost model initialized successfully!\")\n",
    "            return self.model\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\" Model initialization failed: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def train_model(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"Train the XGBoost model\"\"\"\n",
    "        try:\n",
    "            logger.info(\" Training tuned XGBoost model...\")\n",
    "            \n",
    "            self.model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                verbose=50\n",
    "            )\n",
    "            \n",
    "            logger.info(\" Model training completed successfully!\")\n",
    "            return self.model\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\" Model training failed: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"Save trained model and artifacts\"\"\"\n",
    "        try:\n",
    "            logger.info(\" Saving model and artifacts...\")\n",
    "            \n",
    "            # Create directory if it doesn't exist\n",
    "            os.makedirs(self.config.model_dir, exist_ok=True)\n",
    "            \n",
    "            # Save the trained model\n",
    "            joblib.dump(self.model, self.config.trained_model_path)\n",
    "            logger.info(f\" Saved trained model: {self.config.trained_model_path}\")\n",
    "            \n",
    "            # Save training configuration\n",
    "            training_info = {\n",
    "                'model_type': 'XGBoost',\n",
    "                'n_estimators': self.config.n_estimators,\n",
    "                'learning_rate': self.config.learning_rate,\n",
    "                'max_depth': self.config.max_depth,\n",
    "                'training_samples': len(self.train_data),\n",
    "                'feature_dimensions': self.tfidf_vectorizer.transform(['']).shape[1]\n",
    "            }\n",
    "            \n",
    "            info_file = os.path.join(self.config.root_dir, \"training_info.txt\")\n",
    "            with open(info_file, 'w') as f:\n",
    "                f.write(\"=== MODEL TRAINING INFORMATION ===\\n\")\n",
    "                for key, value in training_info.items():\n",
    "                    f.write(f\"{key}: {value}\\n\")\n",
    "            \n",
    "            logger.info(f\" Saved training information: {info_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\" Failed to save model: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Complete model training pipeline (only training, no evaluation)\"\"\"\n",
    "        try:\n",
    "            # Check if model already exists\n",
    "            if self._check_model_exists():\n",
    "                logger.info(\" Model already exists in artifacts/model_training. Skipping training.\")\n",
    "                return {\n",
    "                    'status': 'skipped',\n",
    "                    'message': 'Model already exists',\n",
    "                    'model_path': self.config.trained_model_path\n",
    "                }\n",
    "            \n",
    "            logger.info(\" Starting Model Training Pipeline...\")\n",
    "            \n",
    "            # Step 1: Prepare data\n",
    "            X_train, X_test, y_train, y_test = self.prepare_data()\n",
    "            \n",
    "            # Step 2: Initialize model\n",
    "            self.initialize_model()\n",
    "            \n",
    "            # Step 3: Train model\n",
    "            self.train_model(X_train, X_test, y_train, y_test)\n",
    "            \n",
    "            # Step 4: Save model\n",
    "            self.save_model()\n",
    "            \n",
    "            logger.info(\" Model Training completed successfully!\")\n",
    "            \n",
    "            return {\n",
    "                'status': 'completed',\n",
    "                'message': 'Model trained and saved successfully',\n",
    "                'model_path': self.config.trained_model_path,\n",
    "                'training_samples': len(self.train_data),\n",
    "                'test_samples': len(self.test_data)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\" Model training pipeline failed: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-22 22:29:26,840: INFO: 1034920712: >>>>>> Stage Model Trainer stage started <<<<<<]\n",
      "[2025-10-22 22:29:26,962: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-10-22 22:29:26,962: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-10-22 22:29:26,962: INFO: common: created directory at: artifacts]\n",
      "[2025-10-22 22:29:26,962: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-10-22 22:29:26,978: INFO: DataTransformation:  Data transformation already completed successfully. Skipping...]\n",
      "[2025-10-22 22:29:26,985: INFO: DataTransformation:  Transformation artifacts verified and valid]\n",
      "[2025-10-22 22:29:26,986: INFO: DataTransformation:  Loading existing transformation artifacts...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Science\\END to END Proj\\NVDNLP\\venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\Data Science\\END to END Proj\\NVDNLP\\venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\Data Science\\END to END Proj\\NVDNLP\\venv\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.2.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-22 22:29:36,887: INFO: DataTransformation:  Successfully loaded existing transformation artifacts]\n",
      "[2025-10-22 22:29:36,887: INFO: common: created directory at: artifacts/model_training]\n",
      "[2025-10-22 22:29:36,887: INFO: 1165736424:  Model already exists in artifacts/model_training. Skipping training.]\n",
      "[2025-10-22 22:29:37,430: INFO: 1034920712: >>>>>> Stage Model Trainer stage skipped (model already exists) <<<<<<\n",
      "\n",
      "x==========x]\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ðŸ¤– MODEL TRAINING PIPELINE\n",
    "# ============================================\n",
    "\n",
    "from src.NVDNLP.config.configuration import ConfigurationManager\n",
    "from src.NVDNLP.components.DataTransformation import DataTransformation\n",
    "# from src.NVDNLP.components.ModelTrainer import ModelTrainer\n",
    "from src.NVDNLP import logger\n",
    "\n",
    "STAGE_NAME = \"Model Trainer stage\"\n",
    "\n",
    "class ModelTrainerTrainingPipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "        config = ConfigurationManager()\n",
    "        \n",
    "        # Load data transformation artifacts\n",
    "        data_transformation_config = config.get_data_transformation_config()\n",
    "        data_transformation = DataTransformation(config=data_transformation_config)\n",
    "        transformation_result = data_transformation.transform()\n",
    "        \n",
    "        # Get model trainer config\n",
    "        model_trainer_config = config.get_model_trainer_config()\n",
    "        \n",
    "        # Initialize and train model\n",
    "        model_trainer = ModelTrainer(\n",
    "            config=model_trainer_config,\n",
    "            train_data=transformation_result['train_df'],\n",
    "            test_data=transformation_result['test_df'],\n",
    "            label_encoder=transformation_result['label_encoder'],\n",
    "            tfidf_vectorizer=transformation_result['tfidf_vectorizer']\n",
    "        )\n",
    "        \n",
    "        # Train model (will skip if already exists)\n",
    "        training_result = model_trainer.train()\n",
    "        \n",
    "        return training_result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        logger.info(f\">>>>>> Stage {STAGE_NAME} started <<<<<<\")\n",
    "        obj = ModelTrainerTrainingPipeline()\n",
    "        result = obj.main()\n",
    "        \n",
    "        if result['status'] == 'completed':\n",
    "            logger.info(f\" Model trained successfully!\")\n",
    "            logger.info(f\" Training samples: {result['training_samples']}\")\n",
    "            logger.info(f\" Test samples: {result['test_samples']}\")\n",
    "            logger.info(f\" Model saved at: {result['model_path']}\")\n",
    "            logger.info(f\">>>>>> Stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n",
    "        else:\n",
    "            logger.info(f\">>>>>> Stage {STAGE_NAME} skipped (model already exists) <<<<<<\\n\\nx==========x\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
